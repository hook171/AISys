{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "NAIVE_BAYES_CG_UNSOLVED.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT1mFC4NLgnk"
      },
      "source": [
        "### Наивный байесовский классфикатор."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoiNld1yLgnl"
      },
      "source": [
        "Многие из вас могли слышать про [теорему Байеса](http://mathprofi.ru/formula_polnoj_verojatnosti_formuly_bajesa.html) из курса матстата и теории вероятностей:\n",
        "\n",
        "$\\large P(A_i|B) = \\frac{P(A_iB)}{P(B)} =  \\frac{P(B \\mid A_i)\\, P(A_i)}{P(B)}$\n",
        "\n",
        "Кратко опишем смысл формулы:  \n",
        "\n",
        "_Пусть некое событие $B$ может наступить в результате осуществеления одной из гипотез $A_1$, $A_2$, $A_3$ и тд.  \n",
        "Зная вероятности гипотез $A$ до наступления события, можно, уже после свершения события $B$, вычислить, какая из гипотез привела к свершению этого события с наибольшей вероятностью._\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HFKle3KLgnn"
      },
      "source": [
        "В примере выше у нас был только один признак (курение), но что делать, если признаков больше одного?  \n",
        "\n",
        "Формула изменится таким образом:\n",
        "\n",
        "$ P(A_i|B_1, B_2, ... , B_n) = \\frac{P(B_1, B_2, ... , B_n | A_i)*P(A_i)}{P(B)}$\n",
        "\n",
        "Условная вероятность в числителе расписывается на произведение вероятностей. Тут есть важный нюанс - мы наивно предполагаем, что признаки $B_1$, $B_2$, ... , $B_n$ независимы друг от друга, то есть они никак не коррелируют друг с другом:\n",
        "\n",
        "$ P(B_1, B_2, ... , B_n | A_i) = P(B_1 | A_i) * P(B_2 | A_i) *\\ ...\\ * P(B_n | A_i) $\n",
        "\n",
        "Значит, перед использованием классификатора в идеале необходимо проверить все признаки на взаимную корреляцию, и удалить сильно коррелирующие. Для поиска можно использовать [критерий Пирсона](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-fUZMSLgnm"
      },
      "source": [
        "Априорные и апостериорные вероятности и так далее - это конечно интересно, но где тут связь с классификацией?! Вспомним типичную задачку на теорему байеса:  \n",
        "\n",
        "**_В выборке 40% мужчин и 60% женщин. Известно, что среди них курит 10% женщин и 70% мужчин. Про некоего человека N известно, что он курит. Мужчина он, или женщина?_**\n",
        "\n",
        "Данная задачка по сути есть классификация - у нас есть значение нецелевого признака (курение), и на основе этого нам надо предсказать пол. Решение задачки очень простое, так как все нужные нам числа прописаны сразу в условии:\n",
        "\n",
        "$P(M) = 0.4$  \n",
        "$P(Ж) = 0.6$  \n",
        "$P(K|M) = 0.7$ - вероятность того, что человек курит (К) если он мужчина.  \n",
        "$P(К|Ж) = 0.1$ - вероятность того, что человек курит, если он женщина.  \n",
        "\n",
        "Понятно, что является человек мужчиной или женщиной - это гипотезы, а вероятность того, что курит или не курит - событие, которое может произойти в результате наступления этих гипотез.  \n",
        "Рассчитаем полную вероятность того, что человек курит:\n",
        "$P(К) = P(M)*P(K|M) + P(Ж)*P(К|Ж) = 0.34$.\n",
        "\n",
        "Теперь мы сможем наконец предсказать пол человека зная, курит он (она?) или нет:\n",
        "\n",
        "$P(M|К) = \\frac{P(К|М)*P(M)}{P(К)} = 28/34$\n",
        "\n",
        "$P(Ж|К) = \\frac{P(К|Ж)*P(Ж)}{P(К)} = 6/34$\n",
        "\n",
        "Видно, что тут у нас есть вероятности всех классов. Выбираем просто класс с наибольшей вероятностью (argmax) - и это мужчина. Очевидный плюс такого классифкатора - не требуется большой объем данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PGX5TFJLgno"
      },
      "source": [
        "Любопытно, что если реализовывать классификатор \"в лоб\", по определению теоремы байеса, то точность его будет не высока, так как не учитывается то, каким образом распределены сами данные. Подробно про разные варианты байесовского классификатора можно почитать [тут](https://scikit-learn.org/stable/modules/naive_bayes.html). В данной работе мы будем реализовывать [несколько упрощенный мультиномиальный классификатор](http://bazhenov.me/blog/2012/06/11/naive-bayes.html). Настоятельно рекомендую **прочесть пример** по ссылке и разобраться, каким образом высчитываются все параметры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51JEID56Lgno"
      },
      "source": [
        "### Пред-подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-CH-x9yLgnp"
      },
      "source": [
        "Для начала мы разберемся с данными, а затем реализуем классификатор.\n",
        "\n",
        "Говоря о самих данных, то мы попробуем решить задачу классификации [новостных текстов](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) - байесовские классификаторы часто используются в этой прикладной области машинного обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANyLqj0XLgnp",
        "outputId": "9b5921dd-ab0b-46e0-b555-cbce8e7599bb"
      },
      "source": [
        "# посмотрим на данные - в этот раз датасет доступен напрямую из sklearn.\n",
        "# выведем все доступные категории.\n",
        "# параметр subset отвечает за разделенение данных (train - тренировочная выборка, test - тестовая).\n",
        "\n",
        "# параметр remove говорит о том, какие части данных нужно удалить, чтобы не допустить переобучения.\n",
        "# headers - заголовки новостных групп\n",
        "# quotes - удаление строк, похожих на цитаты из других источников\n",
        "# footers - удаление блоков из конца текста, похожих на подписи\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_train.target_names"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZengtNm_Lgns"
      },
      "source": [
        "Мы будем использовать только 4 класса текстов: `alt.atheism`, `sci.space`, `talk.religion.misc`, `comp.graphics`.  Используя параметр `categories` в функции `fetch_20newsgroups`, задайте список нужных нам категорий и разбейте данные на тренировочную и тестовые части (параметр `subset`).\n",
        "\n",
        "Учтите, что сами данные (целевые и нецелевые признаки) лежат в атрибутах `data` и `target`:\n",
        "```python\n",
        "subset = fetch_20newsgroups( ... )\n",
        "X = subset.data\n",
        "y = subset.target\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEN5cAq3Lgns"
      },
      "source": [
        "categories = ('alt.atheism', 'sci.space', 'talk.religion.misc', 'comp.graphics')\n",
        "\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(\n",
        "    subset='train',\n",
        "    remove=('headers', 'footers', 'quotes'),\n",
        "    categories = categories)\n",
        "\n",
        "newsgroups_test = fetch_20newsgroups(\n",
        "    subset='test',\n",
        "    remove=('headers', 'footers', 'quotes'),\n",
        "    categories = categories)\n",
        "\n",
        "x_train = newsgroups_train.data\n",
        "x_test = newsgroups_test.data\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_GZP6zJLgnt"
      },
      "source": [
        "Посмотрим на типы данных: видно, что X - это список со строками, а y - просто массив с метками класса."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CGx11VSLgnt",
        "outputId": "c113cfa7-60da-4a01-bf06-cdef23c5c1a8"
      },
      "source": [
        "print(type(x_train))\n",
        "print(type(x_train[0]))\n",
        "print(type(y_train))\n",
        "print(type(y_train[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'str'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3mGN3_ALgnu"
      },
      "source": [
        "Выведите на экран по 1 тексту из каждой категории."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZTBntG4Lgnu",
        "outputId": "8fc4220d-8e72-4104-8e4b-0d325ba767e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_texts = {}\n",
        "\n",
        "# Сохраняем по одному тексту для каждой категории\n",
        "for text, category in zip(x_train, y_train):\n",
        "    if category not in example_texts:\n",
        "        example_texts[category] = text\n",
        "\n",
        "# Выводим по одному тексту из каждой категории\n",
        "for category, text in example_texts.items():\n",
        "    print(f\"Category: {newsgroups_train.target_names[category]}\\nText: {text[:200]}...\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: comp.graphics\n",
            "Text: Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and o...\n",
            "\n",
            "Category: talk.religion.misc\n",
            "Text: \n",
            "\n",
            "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
            "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
            "folks with him, children and all, to satisfy his del...\n",
            "\n",
            "Category: sci.space\n",
            "Text: \n",
            " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
            "\n",
            "MB>                                                             So the\n",
            "MB> 1970 figure seems unlikely to actually be any...\n",
            "\n",
            "Category: alt.atheism\n",
            "Text: I have a request for those who would like to see Charley Wingate\n",
            "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
            "appear to be quite a few of you.)  \n",
            "\n",
            "It is clear that Mr. Wingat...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q107gR1lLgnv"
      },
      "source": [
        "проведем небольшой эксперимент по отбору признаков: датасет изкоробочный, специально для обучения машинному обучению (sic), НО...  \n",
        "... проверим данные на наличие пробелов и пустых строк"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk59sXkXLgnv",
        "outputId": "3c1e0a8e-9598-4081-da3a-250a99bea9de"
      },
      "source": [
        "print(x_train.count(''))\n",
        "print(x_train.count(' '))\n",
        "print(x_train.count('  '))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n",
            "4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8CxsEhrLgnw"
      },
      "source": [
        "Как мы видим, среди признаков внезапно оказались пустые строки, и этим пустым строкам присвоен класс! Очевидно, что такое недопустимо, поэтому датасет необходимо немного вычистить.  \n",
        "\n",
        "Заметьте, что мы делаем проверку на строку с 1м, 2мя, 3мя пробелами, но не с 5 пробелами и больше. Чтобы эффективно найти строки с некоторым неизвестным числом пробелов, чтоит воспользоваться регулярным выражением `^\\\\s*$` - данная регулярка срабатывает на строках, состоящих целиком из пробелов (`\\s` - это пробельный символ, квантификатор `*` указывает, что число повторений такого символа больше одного, символ `^` указывает на начало строки, а знак доллара- на конец строки).\n",
        "\n",
        "Для нахождения возьмем функцию `match` из библиотеки `re` регулярных выражений в питоне.  \n",
        "Доки по функции [match](https://docs.python.org/3/library/re.html#re.match). Обратите внимание, что она возвратит `None`, если паттерн не совпал с заданной строкой, или возвратит некий `match object`, если будет совпадение.  \n",
        "\n",
        "**Задача:** в тестовой и тренировочной выборках найти индексы пробельных строк. Зная индексы (это должен быть массив индексов), можно удалить такие элементы из тренировочной и тестовой выборок. Для удаления можете использовать логические маски, или [np.delete](https://numpy.org/doc/stable/reference/generated/numpy.delete.html)\n",
        "\n",
        "**Hints**\n",
        "- np.delete\n",
        "- re.match\n",
        "- '''^\\\\s*$'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly0SwGwkLgnw"
      },
      "source": [
        "Напечатаем число элементов до очистки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im9ZV2OZLgnw",
        "outputId": "83b957b3-27bf-40c3-845b-6cab0adebe0e"
      },
      "source": [
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2034\n",
            "1353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsPBJdA3Lgnx",
        "outputId": "8a180d69-c41b-444e-8d81-159bca3ba3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "pattern = re.compile(r'^\\s*$')\n",
        "\n",
        "# Находим индексы пустых строк в тренировочных и тестовых данных\n",
        "empty_train_indices = [i for i, text in enumerate(x_train) if pattern.match(text)]\n",
        "empty_test_indices = [i for i, text in enumerate(x_test) if pattern.match(text)]\n",
        "\n",
        "# Удаляем пустые строки из тренировочных и тестовых данных\n",
        "x_train = np.delete(x_train, empty_train_indices)\n",
        "y_train = np.delete(y_train, empty_train_indices)\n",
        "x_test = np.delete(x_test, empty_test_indices)\n",
        "y_test = np.delete(y_test, empty_test_indices)\n",
        "\n",
        "# Выводим количество удалённых элементов для проверки\n",
        "print(f\"Удалено {len(empty_train_indices)} пустых строк из тренировочных данных.\")\n",
        "print(f\"Удалено {len(empty_test_indices)} пустых строк из тестовых данных.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удалено 57 пустых строк из тренировочных данных.\n",
            "Удалено 35 пустых строк из тестовых данных.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFfVJ7G9Lgny"
      },
      "source": [
        "Выведем число элементов после очистки, должно получиться 1977 и 1318 элементов в тренировочной и тестовой выборках:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fagvq0cDLgny"
      },
      "source": [
        "assert len(y_train) == 1977\n",
        "assert len(x_train) == 1977\n",
        "assert len(y_test) == 1318\n",
        "assert len(x_test) == 1318"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Ce0CS80QNO"
      },
      "source": [
        "Посмотрим на то, что из себя представляют целевые признаки. Это целое число, обозначающее индекс категории."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGxd_WiU0NkG",
        "outputId": "15ab51e8-60af-4e0c-db85-389e4c359782"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbacr8Dh0olZ"
      },
      "source": [
        "Преобразуем этот индекс в имя категории. Для этого воспользуемся генератором списков и методом `target_names`, который по индексу вернет нам название категории."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sUndLwf0oDE"
      },
      "source": [
        "y_test = [newsgroups_test.target_names[idx] for idx in y_test]\n",
        "y_train = [newsgroups_train.target_names[idx] for idx in y_train]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vaYpBsX2ADT",
        "outputId": "3d95ac32-22a5-4f62-eb61-0fa5bede62da"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc'],\n",
              "      dtype='<U18')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2qqYzkLLgnz"
      },
      "source": [
        "### Как извлечь информацию из текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWsJ4rDvLgnz"
      },
      "source": [
        "В предыдущей части вы подготовили сам датасет, состоящий из строк с символами. Но каким образом конвертировать символы в числа, чтобы предложение образовало точку в некотором многомерном пространстве?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjV9C_21Lgnz"
      },
      "source": [
        "Для этого есть несколько способов:\n",
        "- Счетчики\n",
        "- Распределенная семантика\n",
        "\n",
        "**Счетчики** работают довольно просто - из слов всех предложений выборки вы формируете один большой словарь, и, получая новое предложение, просто считаете, сколько раз каждое слово из словаря было представлено в этом предложении. Таким образом, ваше предложение закодировано вектором, длина которого равна длине словаря. Недостатков у этого метода только два: получающийся вектор имеет очень большую длину, и к тому же он сильно разряжен (в нем много нулей, так как одно предложение априори не может содержать всех слов), из-за чего с ним трудно работать. Второй недостаток - мы просто смотрим на сам _факт наличия_ слова в предложении, но не на _контекст_ этого слова.\n",
        "\n",
        "Оба этих недостатка успешно забарывают методы, основанные на **распределенной семантике**, такие как легендарный Word2Vec и известный GloVe. Такие методы основаны на недо-нейронных сетях, поволяют учитывать контекст слова, и позволяют создавать вектора заданной пользователем длины.\n",
        "\n",
        "Проблема их в том, что значения таких векторов - это и отрицательные числа, а байесовская модель работает только с натуральными. К тому же, такие алгоритмы работают на уровне слова, а не предложения - у вас просто будет набор векторов, представляющих каждое слово из предложения, а каким образом представить вектор самого предложения с наименьшими потерями информации - вопрос.  Поэтому далее мы будем использовать именно счетчики."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ifetN0Lgn0"
      },
      "source": [
        "Для работы со счетчиками мы возьмем реализацию из библиотеки `sklearn`.  \n",
        "\n",
        "по ссылке [тут](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) можно почитать про сами счетчики (мешок слов и TF-IDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KvV7CvyLgn1"
      },
      "source": [
        "#### **Мешок слов**\n",
        "\n",
        "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)\n",
        "\n",
        "Можно начать с очень простой идеи. Давайте разобъем все предложения на слова. Составим словарь всех слов, которые будут встречаться во всех  наших текстах. И отметим, встречается ли это слово в нашем конкретном примере. Другими словами, пусть в таблице в строках будут предложения, в столбцах - слова, а в ячейках число, которое показывает сколько раз это слово встречалось в этом предложении. Получается, что каждому объекту выборки будет сопоставлен вектор.\n",
        "\n",
        "Векторизацию мы делаем сразу методом `fit_transform` - он эквивалентен последовательному вызову\n",
        "```python\n",
        "bow = count_vectorizer.fit(data).transform(data)\n",
        "```\n",
        "\n",
        "Очевидно, что метод `fit` составляет словарь, а `transform` делает вектор из предложения, согласно имеющемуся словарю."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVvPgtemLgn1",
        "outputId": "2fba812d-abd1-462d-cb8c-65a0b524d660"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "texts = [\n",
        "    \"I've been searching for the right words to thank you for this breather.\",\n",
        "    \"You have been wonderful and a blessing at all times\",\n",
        "    \"I promise i wont take your help for granted and will fulfil my promise.\"\n",
        "]\n",
        "bow = count_vectorizer.fit_transform(texts)\n",
        "print(\"Shape=\", bow.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape= (3, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFaq7qzZLgn2",
        "outputId": "a127d05e-ddce-41c6-d780-18fb15365381"
      },
      "source": [
        "# посмотрим на словарь всех слов (метод vocabulary_)\n",
        "# число - это индекс слова в строке матрицы\n",
        "\n",
        "count_vectorizer.vocabulary_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ve': 21,\n",
              " 'been': 3,\n",
              " 'searching': 14,\n",
              " 'for': 6,\n",
              " 'the': 17,\n",
              " 'right': 13,\n",
              " 'words': 25,\n",
              " 'to': 20,\n",
              " 'thank': 16,\n",
              " 'you': 26,\n",
              " 'this': 18,\n",
              " 'breather': 5,\n",
              " 'have': 9,\n",
              " 'wonderful': 23,\n",
              " 'and': 1,\n",
              " 'blessing': 4,\n",
              " 'at': 2,\n",
              " 'all': 0,\n",
              " 'times': 19,\n",
              " 'promise': 12,\n",
              " 'wont': 24,\n",
              " 'take': 15,\n",
              " 'your': 27,\n",
              " 'help': 10,\n",
              " 'granted': 8,\n",
              " 'will': 22,\n",
              " 'fulfil': 7,\n",
              " 'my': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPPj1XurLgn3"
      },
      "source": [
        "Теперь составим ту самую матрицу, где в столбцах слова, а в строках тексты.\n",
        "\n",
        "Как мы видим, в первом и втором предложениях есть слово \"been\", а в третьем его нет (так как у \"been\" индекс равен 3).  \n",
        "Так как векторайзер возвращает разряженную матрицу, то воспользуемся методом `.toarray()`, чтобы превратить ее в numpy-массив."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03EpcKYYLgn4",
        "outputId": "831d31e5-3a72-47ad-b890-25e9cbaa2677"
      },
      "source": [
        "bow.toarray()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "        0, 0, 0, 1, 1, 0],\n",
              "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ULPT499Lgn4"
      },
      "source": [
        "При векторизации можно удалить \"стоп-слова\" - они не несут какого-то смысла, но нужны для грамматики (параметр `stop_words`). Как мы видим, словарь стал заметно меньше, соответсвенно и вектор тоже стал короче."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZWkXFwYLgn4",
        "outputId": "cb77f26c-9eef-4874-9778-6a15ffc4601a"
      },
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "bow = count_vectorizer.fit_transform(texts)\n",
        "print(\"Shape=\", bow.shape)\n",
        "count_vectorizer.vocabulary_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape= (3, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ve': 10,\n",
              " 'searching': 7,\n",
              " 'right': 6,\n",
              " 'words': 13,\n",
              " 'thank': 8,\n",
              " 'breather': 1,\n",
              " 'wonderful': 11,\n",
              " 'blessing': 0,\n",
              " 'times': 9,\n",
              " 'promise': 5,\n",
              " 'wont': 12,\n",
              " 'help': 4,\n",
              " 'granted': 3,\n",
              " 'fulfil': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H77xYv43Lgn5"
      },
      "source": [
        "#### **TF-IDF**\n",
        "\n",
        "[Документация в sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "\n",
        "Мешок слов не учитывает \"веса\" слов, он просто смотрит их вхождение в документ. Вероятно, было бы полезно взвесить каким-то образом каждое слово в документе. Действительно, если слово встречается во всех документах, то, наверное, его вес небольшой. А если редкое слово встречается в некоторых документах, то скорее всего оно какое-то узко тематическое.\n",
        "\n",
        "Один из способов взвесить слова - это использовать меру tf-idf, где:\n",
        "\n",
        "**TF - term frequency** - частота слова для каждой статьи\n",
        "\n",
        "$$\\LARGE \\mathrm{tf}(t,d) = \\frac{n_t}{\\sum_k n_k}$$\n",
        "\n",
        "**IDF - inverse document frequency*** — обратная частота документа - уменьшает вес часто встречаемых слов\n",
        "\n",
        "$$\\LARGE \\mathrm{idf}(t, D) =  \\log \\frac{|D|}{|\\{\\,d_i \\in D \\mid t \\in d_{i}\\, \\}|}$$\n",
        "\n",
        "$|D|$ - число документов в корпусе\n",
        "\n",
        "$|\\{\\,d_i \\in D \\mid t \\in d_{i}\\, \\}|$ - число документов из коллекции ${\\displaystyle D}$ , в которых встречается ${\\displaystyle t}$  (когда ${\\displaystyle n_{t}\\neq 0}$ ).\n",
        "\n",
        "**TF-IDF**\n",
        "\n",
        "$$\\LARGE \\operatorname{tf-idf}(t,d,D) = \\operatorname{tf}(t,d) \\times \\operatorname{idf}(t, D)$$\n",
        "\n",
        "\n",
        "Синтаксис такой же, как и у мешка слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6uWHcobLgn5",
        "outputId": "53996661-0586-4935-e595-0cd9cb3e911d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "texts = [\n",
        "    \"I've been searching for the right words to thank you for this breather.\",\n",
        "    \"You have been wonderful and a blessing at all times\",\n",
        "    \"I promise i wont take your help for granted and will fulfil my promise.\"\n",
        "]\n",
        "bow = tfidf_vectorizer.fit_transform(texts)\n",
        "print(\"Shape=\", bow.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape= (3, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDwWgta3Lgn6",
        "outputId": "70cea03b-5b0d-466c-d654-f49e094febf8"
      },
      "source": [
        "tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ve': 10,\n",
              " 'searching': 7,\n",
              " 'right': 6,\n",
              " 'words': 13,\n",
              " 'thank': 8,\n",
              " 'breather': 1,\n",
              " 'wonderful': 11,\n",
              " 'blessing': 0,\n",
              " 'times': 9,\n",
              " 'promise': 5,\n",
              " 'wont': 12,\n",
              " 'help': 4,\n",
              " 'granted': 3,\n",
              " 'fulfil': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j23wuTh9Lgn6",
        "outputId": "61da0fc3-55d7-4f9d-b7f9-af954b80fe5b"
      },
      "source": [
        "bow.toarray()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.40824829, 0.40824829, 0.40824829, 0.        ,\n",
              "        0.40824829, 0.        , 0.        , 0.40824829],\n",
              "       [0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
              "        0.        , 0.57735027, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.35355339, 0.35355339, 0.35355339,\n",
              "        0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.35355339, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khpVDEVgLgn6"
      },
      "source": [
        "#### **Задание**\n",
        "\n",
        "Обратясь к примерам выше и к документации по ссылкам, создайте векторайзеры для подготовленных в предыдущем параграфе данных. Используйте английские стоп-слова.\n",
        "\n",
        "Так как у нас есть две части (тренировочная и тестовая выборки), то векторайзер нужно обучить на словах из обоих выборок (подумайте, почему). Так как у нас питон, а наши выборки это массивы строк, то объеденить их очень просто - просто сложить. После того, как вы обучили векторайзер на всех словах, проведите трансформации отдельно для тестовой, и отдельно для тренировочных частей.\n",
        "\n",
        "Векторизованные части **назовите** `xcv_test/train` для count_vectorizer, и `xTfidf_test/train` для TF-IDF - это нужно для корректной работы тестов и примеров ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roxobqNsLgn7",
        "outputId": "fc894493-a3a4-4970-e356-44a0de01f254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Инициализация CountVectorizer для преобразования текста в матрицу частот\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "xcv_train = count_vectorizer.fit_transform(x_train)  # Обучение и преобразование тренировочных данных\n",
        "xcv_test = count_vectorizer.transform(x_test)        # Преобразование тестовых данных\n",
        "\n",
        "# Инициализация TfidfVectorizer для преобразования текста в матрицу TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "xTfidf_train = tfidf_vectorizer.fit_transform(x_train)  # Обучение и преобразование тренировочных данных\n",
        "xTfidf_test = tfidf_vectorizer.transform(x_test)        # Преобразование тестовых данных\n",
        "\n",
        "# Выводим размеры полученных матриц\n",
        "print(f\"Count Vectorizer - Train Shape: {xcv_train.shape}, Test Shape: {xcv_test.shape}\")\n",
        "print(f\"TF-IDF Vectorizer - Train Shape: {xTfidf_train.shape}, Test Shape: {xTfidf_test.shape}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Vectorizer - Train Shape: (1977, 26576), Test Shape: (1318, 26576)\n",
            "TF-IDF Vectorizer - Train Shape: (1977, 26576), Test Shape: (1318, 26576)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9llJqtHLgn7"
      },
      "source": [
        "Небольшой тест на проверку размерностей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phJ24tZqLgn7"
      },
      "source": [
        "# count vectorizer\n",
        "assert xcv_train.shape == (1977, 26576)\n",
        "assert xcv_test.shape == (1318, 26576)\n",
        "\n",
        "#tf-idf\n",
        "assert xTfidf_train.shape == (1977, 26576)\n",
        "assert xTfidf_test.shape == (1318, 26576)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JAwiOt_Lgn7"
      },
      "source": [
        "<a name=\"clf-description\"></a>\n",
        "### Реализация классификатора\n",
        "\n",
        "Вспомните статью из блога, которая была в самом начале.\n",
        "\n",
        "Модель классификатора строится на основе обучающей выборки.\n",
        "По ней необходимо найти следующюю статистику:  \n",
        "1. Частоты классов в корпусе объектов (сколько объектов принадлежит каждому из классов)  (`classes_stats`)\n",
        "2. Cуммарное число слов в документах каждого класса (`words_per_class`, далее см. $L_c$)\n",
        "3. Частоты слов в пределах каждого класса (`word_freqs_per_class`, далее используется для расчета $W_{ic}$)\n",
        "4. Размер словаря выборки (число признаков) - кол-во уникальных слов в выборке (`num_features`)\n",
        "\n",
        "По сути, это метод `fit` классификатора.\n",
        "\n",
        "На этапе предсказания необходимо воспользоваться следующей формулой:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "predicted\\ class = \\operatorname*{arg\\max}_{c \\in C} \\left[\\log{{D_c} \\over {D}} + \\sum_{i \\in Q}{\\log{{W_{ic} + 1} \\over {|V| + L_c}}}\\right]\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Поясним некоторые переменные в этом выражении:  \n",
        "$D_c$ - количество документов в обуч. выборке $\\in$ классу $c$\n",
        "\n",
        "$D$ - сколько всего было документов в обуч. выборке\n",
        "\n",
        "$|V|$ - количество уникальных слов во сех документах обуч. выборки\n",
        "\n",
        "$L_c$ - cуммарное число слов в документах класса $c$ обучающей выборки\n",
        "\n",
        "$W_{ic}$ - сколько раз $i$ слово встретилось в объектах класса $c$ обучающей выборки\n",
        "\n",
        "$Q$ - множество слов _классифицируемого_ документа\n",
        "\n",
        "Сигнатура класса:\n",
        "\n",
        "```python\n",
        "class NaiveBayes:\n",
        "    def fit(self, x, y) -> None\n",
        "    \n",
        "    def predict(self, x) -> List[Int]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOl06mCYLgn8"
      },
      "source": [
        "Для начала отдельно подсчитаем различные статистики, описанные в статье и в материале выше.\n",
        "Так как у нас уже готовы все данные, то считать будем по **count_vectorizer**'у (то есть xcv_ ...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xit7_y8jLgn8"
      },
      "source": [
        "Общее число документов в обучающей выборке (`doc_num`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHPsWi3eLgn8",
        "outputId": "fef95d56-d9fb-4590-bb7e-a5e6e10ac13b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "train_counts = cv.fit_transform(x_train)\n",
        "test_counts = cv.transform(x_test)\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "train_tfidf = tfidf.fit_transform(x_train)\n",
        "test_tfidf = tfidf.transform(x_test)\n",
        "\n",
        "# Печатаем размеры матриц частот\n",
        "print(\"Shape of training data using CountVectorizer:\", train_counts.shape)\n",
        "print(\"Shape of test data using CountVectorizer:\", test_counts.shape)\n",
        "print(\"Shape of training data using TfidfVectorizer:\", train_tfidf.shape)\n",
        "print(\"Shape of test data using TfidfVectorizer:\", test_tfidf.shape)\n",
        "\n",
        "# Печатаем размеры словарей\n",
        "count_vocab_size = len(cv.vocabulary_)\n",
        "tfidf_vocab_size = len(tfidf.vocabulary_)\n",
        "\n",
        "print(\"Vocabulary size for CountVectorizer:\", count_vocab_size)\n",
        "print(\"Vocabulary size for TfidfVectorizer:\", tfidf_vocab_size)\n",
        "\n",
        "# Общее количество документов\n",
        "doc_num = len(x_train)\n",
        "print(\"Number of documents in the training dataset:\", doc_num)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data using CountVectorizer: (1977, 26576)\n",
            "Shape of test data using CountVectorizer: (1318, 26576)\n",
            "Shape of training data using TfidfVectorizer: (1977, 26576)\n",
            "Shape of test data using TfidfVectorizer: (1318, 26576)\n",
            "Vocabulary size for CountVectorizer: 26576\n",
            "Vocabulary size for TfidfVectorizer: 26576\n",
            "Number of documents in the training dataset: 1977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6rJBGiKaU-7"
      },
      "source": [
        "# ПРОВЕРКА\n",
        "assert doc_num == 1977"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZdjDDTELgn8"
      },
      "source": [
        "Словарь, содержащий число объектов каждого класса (`classes_stats`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APfAvqcyLgn9",
        "outputId": "26d712b1-5ef7-48e9-c40b-54cdb7fd1362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "classes_stats  = Counter(y_train)\n",
        "\n",
        "print(\"Number of objects for each class:\", classes_stats )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of objects for each class: Counter({'sci.space': 577, 'comp.graphics': 571, 'alt.atheism': 468, 'talk.religion.misc': 361})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkyU6KypajSC"
      },
      "source": [
        "# ПРОВЕРКА\n",
        "assert classes_stats['alt.atheism'] == 468\n",
        "assert classes_stats['comp.graphics'] == 571\n",
        "assert classes_stats['sci.space'] == 577\n",
        "assert classes_stats['talk.religion.misc'] == 361"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMPXQjAGLgn9"
      },
      "source": [
        "Число уникальных признаков (слов) в тренировочной выборке (`num_features`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbsLa0wiLgn9",
        "outputId": "f1e830ac-6e24-450b-a5af-d715257c5ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "xcv_train = count_vectorizer.fit_transform(x_train)\n",
        "\n",
        "num_features = len(count_vectorizer.vocabulary_)\n",
        "\n",
        "print(\"Number of unique features (words) in the training dataset:\", num_features)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique features (words) in the training dataset: 26576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1PgsyaHanzE"
      },
      "source": [
        "# ПРОВЕРКА\n",
        "assert num_features == 26576"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7kZMoe1Lgn9"
      },
      "source": [
        "Создадим словарь `indexes`, в котором ключом будет являться имя класса, а значением - список строк матрицы X, принадлежащих этому классу. Этот список пригодится нам дальше, так как будет играть роль маски. Для поиска класса каждой из строк используйте целевой вектор.\n",
        "\n",
        "**Hints:**\n",
        "- [np.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbO1neuVLgn-",
        "outputId": "b8916dba-70c4-4407-c0d5-d284d287ee38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "indexes = {}\n",
        "\n",
        "for index, label in enumerate(y_train):\n",
        "    if label not in indexes:\n",
        "        indexes[label] = []  # Если нет, создаем новый список для этой метки\n",
        "    indexes[label].append(index)  # Добавляем индекс в соответствующий список\n",
        "\n",
        "print(\"Indexes of each class:\", indexes)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexes of each class: {'comp.graphics': [0, 7, 9, 11, 12, 14, 21, 24, 25, 26, 30, 31, 35, 41, 42, 48, 52, 54, 55, 56, 57, 60, 61, 63, 66, 68, 71, 73, 76, 87, 103, 113, 118, 126, 130, 131, 137, 143, 147, 148, 149, 155, 159, 162, 169, 170, 180, 182, 183, 187, 189, 198, 199, 200, 207, 208, 213, 219, 223, 225, 231, 232, 233, 240, 247, 252, 256, 258, 261, 270, 274, 276, 283, 284, 290, 294, 298, 301, 305, 311, 316, 326, 329, 330, 331, 333, 334, 336, 337, 343, 344, 347, 348, 350, 352, 353, 355, 357, 358, 361, 363, 367, 370, 373, 375, 376, 379, 382, 385, 388, 393, 394, 396, 397, 412, 415, 417, 418, 419, 421, 422, 428, 433, 435, 439, 443, 446, 447, 451, 452, 455, 457, 458, 462, 463, 468, 470, 478, 480, 481, 482, 485, 487, 491, 500, 508, 515, 518, 521, 522, 523, 526, 531, 539, 542, 543, 547, 553, 555, 559, 561, 563, 564, 566, 567, 571, 577, 579, 583, 584, 586, 592, 594, 596, 597, 604, 607, 614, 615, 616, 618, 624, 625, 628, 629, 630, 632, 633, 636, 641, 642, 645, 646, 657, 660, 665, 670, 674, 676, 683, 688, 689, 694, 696, 699, 701, 706, 711, 715, 720, 721, 723, 735, 738, 746, 751, 754, 756, 758, 762, 766, 768, 769, 775, 779, 785, 786, 789, 798, 802, 804, 814, 818, 822, 824, 832, 835, 839, 842, 843, 847, 849, 851, 854, 855, 857, 858, 865, 866, 870, 875, 883, 884, 885, 890, 899, 900, 901, 902, 904, 912, 914, 918, 919, 926, 930, 937, 938, 943, 951, 952, 953, 955, 958, 960, 962, 964, 966, 968, 969, 974, 979, 981, 985, 987, 989, 990, 994, 995, 996, 1002, 1003, 1004, 1005, 1010, 1015, 1018, 1021, 1022, 1028, 1031, 1037, 1042, 1046, 1054, 1056, 1060, 1063, 1073, 1078, 1086, 1087, 1091, 1095, 1096, 1100, 1103, 1104, 1110, 1111, 1112, 1113, 1123, 1126, 1128, 1135, 1136, 1139, 1141, 1142, 1152, 1159, 1162, 1163, 1172, 1173, 1179, 1180, 1184, 1186, 1189, 1193, 1194, 1197, 1200, 1208, 1211, 1212, 1213, 1216, 1219, 1221, 1225, 1226, 1229, 1236, 1237, 1238, 1239, 1241, 1249, 1250, 1252, 1256, 1258, 1262, 1264, 1270, 1271, 1272, 1274, 1277, 1282, 1284, 1292, 1293, 1294, 1298, 1308, 1310, 1313, 1314, 1319, 1321, 1322, 1327, 1328, 1329, 1332, 1333, 1335, 1352, 1353, 1354, 1362, 1363, 1364, 1373, 1384, 1386, 1388, 1390, 1397, 1407, 1412, 1414, 1417, 1418, 1426, 1429, 1442, 1445, 1446, 1448, 1449, 1453, 1455, 1457, 1461, 1462, 1471, 1473, 1479, 1480, 1481, 1484, 1485, 1489, 1490, 1497, 1498, 1502, 1503, 1505, 1507, 1509, 1522, 1531, 1533, 1535, 1536, 1538, 1539, 1542, 1544, 1545, 1547, 1549, 1555, 1557, 1558, 1559, 1561, 1565, 1568, 1569, 1571, 1585, 1586, 1591, 1593, 1604, 1614, 1615, 1617, 1618, 1622, 1623, 1625, 1628, 1629, 1631, 1632, 1634, 1647, 1648, 1652, 1653, 1657, 1658, 1662, 1663, 1664, 1666, 1669, 1670, 1675, 1676, 1680, 1685, 1688, 1691, 1692, 1697, 1701, 1703, 1704, 1713, 1714, 1717, 1718, 1720, 1722, 1723, 1724, 1725, 1727, 1729, 1730, 1737, 1739, 1740, 1742, 1744, 1745, 1746, 1750, 1754, 1760, 1763, 1765, 1768, 1771, 1775, 1781, 1784, 1790, 1791, 1792, 1793, 1795, 1799, 1806, 1809, 1819, 1824, 1825, 1826, 1829, 1835, 1836, 1840, 1841, 1842, 1846, 1850, 1853, 1855, 1857, 1860, 1876, 1877, 1880, 1883, 1885, 1886, 1896, 1904, 1907, 1908, 1916, 1917, 1941, 1942, 1943, 1950, 1953, 1963, 1965, 1972, 1975], 'talk.religion.misc': [1, 19, 22, 23, 27, 29, 45, 46, 47, 50, 67, 77, 78, 80, 86, 88, 92, 94, 99, 106, 107, 112, 114, 117, 123, 129, 132, 136, 150, 151, 152, 153, 154, 163, 166, 167, 173, 176, 177, 188, 192, 194, 195, 209, 220, 228, 234, 237, 239, 241, 244, 245, 246, 249, 253, 257, 264, 266, 267, 269, 277, 285, 291, 293, 295, 304, 306, 312, 313, 318, 319, 328, 339, 340, 351, 377, 383, 391, 405, 420, 423, 424, 425, 434, 445, 450, 453, 460, 461, 476, 477, 488, 494, 497, 506, 507, 530, 532, 533, 541, 544, 550, 558, 560, 568, 576, 578, 582, 588, 599, 600, 603, 608, 610, 613, 623, 631, 637, 640, 644, 653, 658, 659, 662, 668, 671, 672, 673, 678, 680, 685, 691, 692, 697, 700, 702, 705, 707, 716, 717, 718, 719, 725, 728, 729, 740, 743, 760, 763, 770, 776, 780, 788, 794, 800, 803, 805, 821, 831, 834, 840, 850, 852, 862, 876, 877, 879, 880, 881, 887, 895, 898, 905, 922, 924, 925, 936, 944, 950, 957, 973, 975, 977, 978, 980, 983, 984, 988, 992, 1001, 1007, 1034, 1035, 1043, 1047, 1048, 1049, 1058, 1067, 1068, 1079, 1080, 1088, 1089, 1099, 1117, 1118, 1125, 1127, 1132, 1143, 1153, 1155, 1157, 1168, 1171, 1176, 1178, 1181, 1188, 1207, 1217, 1240, 1242, 1245, 1255, 1260, 1265, 1273, 1287, 1296, 1300, 1303, 1306, 1307, 1312, 1316, 1324, 1330, 1334, 1336, 1339, 1343, 1346, 1350, 1355, 1356, 1359, 1360, 1361, 1369, 1370, 1372, 1376, 1380, 1394, 1400, 1402, 1404, 1410, 1411, 1427, 1428, 1431, 1432, 1437, 1440, 1443, 1452, 1466, 1467, 1476, 1486, 1491, 1504, 1516, 1518, 1520, 1524, 1530, 1540, 1541, 1546, 1567, 1570, 1573, 1584, 1592, 1594, 1597, 1600, 1601, 1605, 1606, 1607, 1608, 1619, 1637, 1645, 1649, 1650, 1651, 1659, 1667, 1668, 1671, 1677, 1678, 1679, 1681, 1686, 1687, 1708, 1710, 1721, 1726, 1732, 1733, 1748, 1749, 1753, 1756, 1757, 1778, 1783, 1787, 1788, 1796, 1797, 1801, 1804, 1807, 1810, 1812, 1832, 1838, 1844, 1856, 1862, 1864, 1866, 1872, 1887, 1895, 1898, 1899, 1905, 1909, 1918, 1923, 1924, 1925, 1926, 1927, 1930, 1935, 1936, 1937, 1956, 1957, 1959], 'sci.space': [2, 4, 6, 8, 10, 13, 15, 17, 18, 20, 33, 37, 39, 49, 51, 58, 62, 64, 69, 70, 72, 75, 81, 82, 84, 90, 95, 96, 100, 101, 102, 105, 108, 109, 110, 111, 119, 120, 122, 125, 127, 128, 134, 135, 139, 140, 144, 156, 157, 158, 160, 161, 164, 168, 174, 175, 179, 181, 193, 197, 202, 204, 210, 215, 216, 217, 221, 227, 229, 230, 242, 243, 248, 251, 255, 260, 262, 263, 268, 273, 278, 279, 281, 282, 286, 288, 292, 296, 297, 302, 307, 310, 314, 321, 322, 323, 332, 335, 341, 345, 346, 349, 365, 366, 368, 374, 380, 381, 386, 387, 392, 395, 398, 403, 404, 406, 407, 408, 410, 414, 426, 427, 430, 431, 432, 437, 438, 441, 444, 448, 459, 466, 467, 469, 471, 472, 473, 474, 475, 483, 484, 486, 489, 490, 492, 493, 498, 499, 501, 502, 509, 510, 512, 516, 519, 525, 536, 537, 540, 546, 549, 551, 552, 554, 556, 557, 562, 570, 575, 580, 581, 587, 589, 591, 595, 602, 606, 609, 617, 619, 621, 622, 627, 638, 639, 643, 647, 648, 650, 651, 652, 655, 656, 661, 667, 669, 675, 677, 679, 681, 684, 686, 687, 693, 698, 703, 708, 722, 724, 730, 732, 734, 736, 741, 748, 750, 753, 759, 761, 767, 773, 774, 777, 778, 781, 782, 783, 784, 790, 791, 793, 795, 796, 799, 801, 806, 807, 808, 809, 810, 811, 813, 816, 817, 819, 825, 827, 829, 830, 833, 836, 844, 845, 846, 848, 853, 861, 867, 869, 871, 873, 874, 878, 889, 894, 896, 897, 906, 911, 915, 916, 917, 920, 923, 928, 932, 935, 939, 940, 941, 946, 947, 949, 959, 971, 972, 982, 986, 991, 1000, 1011, 1012, 1014, 1016, 1020, 1025, 1030, 1036, 1038, 1039, 1050, 1051, 1052, 1053, 1055, 1057, 1059, 1064, 1065, 1070, 1075, 1076, 1077, 1081, 1082, 1083, 1090, 1092, 1093, 1098, 1101, 1102, 1106, 1107, 1109, 1116, 1119, 1121, 1122, 1124, 1129, 1130, 1131, 1133, 1137, 1138, 1145, 1148, 1150, 1151, 1154, 1161, 1165, 1166, 1167, 1169, 1174, 1177, 1183, 1185, 1187, 1190, 1195, 1196, 1198, 1199, 1201, 1203, 1204, 1205, 1210, 1214, 1215, 1223, 1228, 1231, 1233, 1243, 1246, 1247, 1257, 1259, 1261, 1263, 1268, 1276, 1279, 1281, 1283, 1288, 1289, 1291, 1297, 1302, 1309, 1311, 1318, 1323, 1325, 1326, 1337, 1338, 1341, 1342, 1344, 1345, 1348, 1349, 1351, 1358, 1365, 1367, 1378, 1381, 1382, 1392, 1393, 1396, 1403, 1406, 1408, 1409, 1416, 1419, 1421, 1424, 1425, 1430, 1433, 1436, 1439, 1441, 1444, 1450, 1451, 1460, 1463, 1464, 1468, 1470, 1472, 1474, 1475, 1477, 1482, 1483, 1492, 1493, 1494, 1500, 1508, 1510, 1512, 1513, 1514, 1519, 1521, 1525, 1527, 1528, 1543, 1548, 1550, 1552, 1554, 1563, 1564, 1566, 1575, 1576, 1577, 1583, 1588, 1602, 1609, 1612, 1613, 1620, 1621, 1624, 1626, 1627, 1630, 1633, 1635, 1636, 1638, 1640, 1642, 1643, 1644, 1646, 1655, 1660, 1661, 1672, 1682, 1683, 1684, 1689, 1690, 1694, 1695, 1700, 1702, 1705, 1709, 1712, 1715, 1716, 1728, 1735, 1741, 1743, 1747, 1751, 1752, 1755, 1759, 1764, 1766, 1770, 1773, 1777, 1779, 1780, 1782, 1798, 1800, 1802, 1805, 1808, 1815, 1817, 1818, 1821, 1823, 1828, 1830, 1834, 1837, 1839, 1845, 1847, 1849, 1852, 1858, 1859, 1861, 1863, 1865, 1867, 1871, 1873, 1874, 1875, 1878, 1879, 1882, 1884, 1889, 1890, 1892, 1893, 1897, 1900, 1901, 1906, 1910, 1912, 1914, 1915, 1920, 1921, 1931, 1934, 1947, 1948, 1951, 1955, 1958, 1962, 1964, 1968, 1969, 1973, 1974], 'alt.atheism': [3, 5, 16, 28, 32, 34, 36, 38, 40, 43, 44, 53, 59, 65, 74, 79, 83, 85, 89, 91, 93, 97, 98, 104, 115, 116, 121, 124, 133, 138, 141, 142, 145, 146, 165, 171, 172, 178, 184, 185, 186, 190, 191, 196, 201, 203, 205, 206, 211, 212, 214, 218, 222, 224, 226, 235, 236, 238, 250, 254, 259, 265, 271, 272, 275, 280, 287, 289, 299, 300, 303, 308, 309, 315, 317, 320, 324, 325, 327, 338, 342, 354, 356, 359, 360, 362, 364, 369, 371, 372, 378, 384, 389, 390, 399, 400, 401, 402, 409, 411, 413, 416, 429, 436, 440, 442, 449, 454, 456, 464, 465, 479, 495, 496, 503, 504, 505, 511, 513, 514, 517, 520, 524, 527, 528, 529, 534, 535, 538, 545, 548, 565, 569, 572, 573, 574, 585, 590, 593, 598, 601, 605, 611, 612, 620, 626, 634, 635, 649, 654, 663, 664, 666, 682, 690, 695, 704, 709, 710, 712, 713, 714, 726, 727, 731, 733, 737, 739, 742, 744, 745, 747, 749, 752, 755, 757, 764, 765, 771, 772, 787, 792, 797, 812, 815, 820, 823, 826, 828, 837, 838, 841, 856, 859, 860, 863, 864, 868, 872, 882, 886, 888, 891, 892, 893, 903, 907, 908, 909, 910, 913, 921, 927, 929, 931, 933, 934, 942, 945, 948, 954, 956, 961, 963, 965, 967, 970, 976, 993, 997, 998, 999, 1006, 1008, 1009, 1013, 1017, 1019, 1023, 1024, 1026, 1027, 1029, 1032, 1033, 1040, 1041, 1044, 1045, 1061, 1062, 1066, 1069, 1071, 1072, 1074, 1084, 1085, 1094, 1097, 1105, 1108, 1114, 1115, 1120, 1134, 1140, 1144, 1146, 1147, 1149, 1156, 1158, 1160, 1164, 1170, 1175, 1182, 1191, 1192, 1202, 1206, 1209, 1218, 1220, 1222, 1224, 1227, 1230, 1232, 1234, 1235, 1244, 1248, 1251, 1253, 1254, 1266, 1267, 1269, 1275, 1278, 1280, 1285, 1286, 1290, 1295, 1299, 1301, 1304, 1305, 1315, 1317, 1320, 1331, 1340, 1347, 1357, 1366, 1368, 1371, 1374, 1375, 1377, 1379, 1383, 1385, 1387, 1389, 1391, 1395, 1398, 1399, 1401, 1405, 1413, 1415, 1420, 1422, 1423, 1434, 1435, 1438, 1447, 1454, 1456, 1458, 1459, 1465, 1469, 1478, 1487, 1488, 1495, 1496, 1499, 1501, 1506, 1511, 1515, 1517, 1523, 1526, 1529, 1532, 1534, 1537, 1551, 1553, 1556, 1560, 1562, 1572, 1574, 1578, 1579, 1580, 1581, 1582, 1587, 1589, 1590, 1595, 1596, 1598, 1599, 1603, 1610, 1611, 1616, 1639, 1641, 1654, 1656, 1665, 1673, 1674, 1693, 1696, 1698, 1699, 1706, 1707, 1711, 1719, 1731, 1734, 1736, 1738, 1758, 1761, 1762, 1767, 1769, 1772, 1774, 1776, 1785, 1786, 1789, 1794, 1803, 1811, 1813, 1814, 1816, 1820, 1822, 1827, 1831, 1833, 1843, 1848, 1851, 1854, 1868, 1869, 1870, 1881, 1888, 1891, 1894, 1902, 1903, 1911, 1913, 1919, 1922, 1928, 1929, 1932, 1933, 1938, 1939, 1940, 1944, 1945, 1946, 1949, 1952, 1954, 1960, 1961, 1966, 1967, 1970, 1971, 1976]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmjQZiKLauNb"
      },
      "source": [
        "# ПРОВЕРКА\n",
        "# так как в словаре очень много элементов, то проверим случайные элементы из списка.\n",
        "# если вы все сделали правильно, то эти элементы совпадут.\n",
        "assert indexes['sci.space'][35] == 111\n",
        "assert indexes['comp.graphics'][42] == 159\n",
        "assert indexes['talk.religion.misc'][67] == 312\n",
        "assert indexes['alt.atheism'][89] == 372"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipTcV_I1Lgn-"
      },
      "source": [
        "Используя найденные выше индексы, подсчитаем два важных параметра `words_per_class` и `word_freqs_per_class`.  \n",
        "Обе этих переменных являются словарями, но первая из них отвечает за суммарное число слов, использованных в **каждом классе**, а вторая показывает, сколько раз конкретное слово встретилось в документах определенного класса.  Соответственно, формат переменной `words_per_class` - `{str: int}`, формат `word_freqs_per_class` - `{str: List}`.\n",
        "Мы специально объеденили поиск двух разных статистик в одном блоке, чтобы избежать лишних циклов.\n",
        "\n",
        "Чтобы найти в X строки, относящиеся к тому или иному классу, воспользуйтесь поиском по маске `indexes` для нужного класса.\n",
        "\n",
        "Также помните, что X - это разряженная матрица, но из нее можно получить обычный список через метод `toarray()`\n",
        "\n",
        "**Hints::**\n",
        "- вспомните про маски в numpy-массивах\n",
        "```python\n",
        "mask = [1,0,2] #indexes\n",
        "array = [1,2,4,8,16,32,64,128]\n",
        "array[mask]\n",
        "#result: array([2, 1, 4])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHxuZaP9Lgn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3fa34c-c349-4c93-aa34-4e18dfd4646f"
      },
      "source": [
        "x_arr = xcv_train.toarray()\n",
        "\n",
        "words_per_class = {}\n",
        "word_freqs_per_class = {}\n",
        "\n",
        "for cls in indexes.keys():\n",
        "    class_idxs = indexes[cls] # нашли индексы строк матрицы, относящихся к классу cls\n",
        "\n",
        "    subarray_rows = x_arr[class_idxs] # нашли подмассив, относящийся к  классу cls\n",
        "    subarray_sum = np.sum(subarray_rows, axis = 0) # провели суммирование по столбцам\n",
        "    word_freqs_per_class[cls] = subarray_sum\n",
        "\n",
        "    words_per_class[cls] = len(subarray_sum[subarray_sum != 0]) # узнали,\n",
        "        # сколько слов было использовано в рамках одного класса,\n",
        "        # то есть просто подсчитали число ненулевых элементов\n",
        "\n",
        "words_per_class, word_freqs_per_class"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'comp.graphics': 10592,\n",
              "  'talk.religion.misc': 8860,\n",
              "  'sci.space': 13273,\n",
              "  'alt.atheism': 8737},\n",
              " {'comp.graphics': array([26, 12,  0, ...,  0,  0,  2]),\n",
              "  'talk.religion.misc': array([1, 9, 0, ..., 0, 0, 0]),\n",
              "  'sci.space': array([32, 92,  2, ...,  1,  2,  0]),\n",
              "  'alt.atheism': array([ 0, 17,  0, ...,  0,  0,  0])})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GSxOKIxLgn_"
      },
      "source": [
        "Все вышенаписанные переменные образуют метод `fit` будущего классификатора. Теперь внесите этот код в метод fit, и не забудьте сделать найденные переменные полями экземпляра класса при помощи `self`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4COT-aNDLgn_"
      },
      "source": [
        "Теперь реализуем метод `predict`. Вспомните еще раз [большую формулу](#clf-description) из начала этого раздела. Если вы внимательно читали статью, то заметили, что в примере мы получили не чистые вероятности классов, а всего лишь числовые оценки. Далее эти оценки можно перевести в вероятности, но мы этого делать не будем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7dnSPbILgn_"
      },
      "source": [
        "Тогда промежуточный выход классификатора обозначим так:\n",
        "\n",
        "`pred_per_class = {<номер строки в тестовой выборке>: {<класс 1>: <оценка>, ... , <класс n>: <оценка>}}`\n",
        "\n",
        "Таким образом итоговый класс к которому будет отнесена строка - просто класс с наибольшей оценкой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo7EWqLHLgoA"
      },
      "source": [
        "Не забудьте о следующих вещах:\n",
        "- X_test - это такая же разряженная матрица, нужно превратить ее в список\n",
        "- переменная $\\frac{D_c}{D}$ одинакова для одного класса.\n",
        "- Чтобы подсчитать $W_{ic}$ воспользуйтесь `word_freqs_per_class`.\n",
        "- Чтобы понять, какие элементы вам нужно брать в `word_freqs_per_class`, найдите индексы ненулевых элементов в классифицируемой строке - если эти элементы ненулевые, значит, там было какое-то слово\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iws9JGvsdoHl"
      },
      "source": [
        "**Hints:**\n",
        "- [np.nonzero](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html) (будьте внимательны с типом возвращаемого значения!)\n",
        "- [Math.log](https://docs.python.org/3/library/math.html) для чисел\n",
        "- [np.log](https://numpy.org/doc/stable/reference/generated/numpy.log.html) для массивов\n",
        "- Так как с каждым разом вы добавляете оценку для нового класса, логично использовать [defaultdict(dict)](https://docs.python.org/3/library/collections.html#collections.defaultdict): так создается словарь, состоящий из пустых словарей, и при обращении к элементу словаря, например `pred_per_class['SomeID']` мы получаем словарь, для которого доступны все стандартные методы (например, update)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o7Oz-WfLgoA"
      },
      "source": [
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        self.num_features = x_train.shape[1]\n",
        "        self.doc_num = x_train.shape[0]\n",
        "        self.classes_stats = Counter(y_train)\n",
        "\n",
        "        self.indexes = {}\n",
        "        for index, label in enumerate(y_train):\n",
        "            if label not in self.indexes:\n",
        "                self.indexes[label] = []\n",
        "            self.indexes[label].append(index)\n",
        "\n",
        "        x_arr = x_train.toarray()\n",
        "        self.words_per_class = {}\n",
        "        self.word_freqs_per_class = {}\n",
        "\n",
        "        for cls in self.indexes.keys():\n",
        "            class_idxs = self.indexes[cls]\n",
        "            subarray_rows = x_arr[class_idxs]\n",
        "            self.word_freqs_per_class[cls] = np.sum(subarray_rows, axis=0)\n",
        "            self.words_per_class[cls] = np.sum(self.word_freqs_per_class[cls])\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        x_test_arr = x_test.toarray()\n",
        "        preds = []\n",
        "\n",
        "        for doc in x_test_arr:\n",
        "            pred_per_class = defaultdict(float)\n",
        "\n",
        "            for cls in self.classes_stats.keys():\n",
        "                log_prior = math.log(self.classes_stats[cls] / self.doc_num)\n",
        "                non_zero_indices = np.nonzero(doc)[0]\n",
        "\n",
        "                log_likelihood = 0\n",
        "                for idx in non_zero_indices:\n",
        "                    word_count = self.word_freqs_per_class[cls][idx]\n",
        "                    log_likelihood += math.log((word_count + 1) / (self.num_features + self.words_per_class[cls]))\n",
        "\n",
        "                pred_per_class[cls] = log_prior + log_likelihood\n",
        "\n",
        "            predicted_class = max(pred_per_class, key=pred_per_class.get)\n",
        "            preds.append(predicted_class)\n",
        "\n",
        "        return preds"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJyBqIc7fo10"
      },
      "source": [
        "### Проверка классификатора\n",
        "\n",
        "Воспользуемся матрицей ошибок и отчетом классификации из `sklearn`, проверим классификатор и на count_vectorizer-векторах, и на tf-idf-векторах. Для начала поговорим о способах оценки качества классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPpD5E193W0B"
      },
      "source": [
        "#### Матрица ошибок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4EgZ5ow3b3Q"
      },
      "source": [
        "Основной материал можете прочесть в [статье](https://habr.com/ru/company/ods/blog/328372/), тут же напишем кратко."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osbSv3zY3xDU"
      },
      "source": [
        "Рассмотрим матрицу:\n",
        "\n",
        "\n",
        " <br></br> | $y=1$ | $y=0$\n",
        "--- | --- | ---\n",
        "$\\overline{y} = 1$ | **True Positive (TP)** | **False Positive (FP)**\n",
        "$\\overline{y} = 0$ | **False Negative (FN)** | **True Negative (TN)**\n",
        "\n",
        "$y$ - истинная метка класса, $\\overline{y}$ - предсказание классификатора.\n",
        "\n",
        "По главной диагонали матрицы - число правильно классифицированных объектов (TP и FP).  \n",
        "\n",
        "Понятно, что число классов может быть больше двух, но для простоты будем рассматривать только случай с двумя классами, назовем их условно Positive и Negative.\n",
        "\n",
        "Ошибки бывают двух типов: **ошибки первого рода** (FP), или ложноположительное срабатывание, когда, например, анализ показывает заболевание, хотя на самом деле человек здоров, и **ошибки второго рода** (FN), или пропуск события, когда больного человека принимают за здорового.\n",
        "\n",
        "В некотрых случаях по оси X может отображаться предсказание модели, а по оси Y - истинные метки. Важно не запоминать положение элементов в матрице, а в зависимости от заданных осей понимать, где ошибки, а где правильные значения.\n",
        "\n",
        "**Метрики**\n",
        "\n",
        "_Accuracy_, или точность.  \n",
        "Обозначает в целом долю правильных ответов:\n",
        "\n",
        "$$\n",
        "Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}\n",
        "$$\n",
        "\n",
        "Недостаток метрики в том, что она не работает на несбалансированных выборках.\n",
        "\n",
        "_Precision_ и _Recall_, или точность и полнота.  \n",
        "\n",
        "---\n",
        "\n",
        "**Важное замечание**  \n",
        "_Оба термина переводятся на русский язык как точность, хотя при этом отражают разные понятия. Чтобы не допустить недопонимая, можно использовать английские слова напрямую, либо accuracy называть аккуратностью, а precision - точностью. Полнота - она и есть полнота._\n",
        "\n",
        "---\n",
        "\n",
        "Эти две метрики рассчитываются отдельного для каждого из классов. Для примера рассмотрим класс Positive:\n",
        "\n",
        "$$\n",
        "Precision = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "$$\n",
        "Recall = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "Precision отражает долю объектов класса Positive, которые классификатор классифицировал верно.\n",
        "\n",
        "Recall показывает долю объектов класса Positive среди всех объектов класса Positive, которые вообще нашел алгоритм.\n",
        "\n",
        "F-мера - один из способов объеденить Precision и Recall:\n",
        "\n",
        "$$\n",
        "F_\\beta = (1 + \\beta^2) \\cdot \\frac{Precision \\cdot Recall}{\\beta^2 \\cdot Precision + Recall}\n",
        "$$\n",
        "\n",
        "$\\beta$ - вес Precision в метрике.\n",
        "\n",
        "В `sklearn` за матрицу ошибок и метрики отвечают [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) и [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BKyh41ZLgoB",
        "outputId": "6021fccf-3783-4bf6-ea2a-d7dda6fb55e3"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "nb = NaiveBayes()\n",
        "\n",
        "nb.fit(xcv_train, y_train)\n",
        "pred = nb.predict(xcv_test)\n",
        "\n",
        "print(classification_report(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       alt.atheism       0.65      0.76      0.70       311\n",
            "     comp.graphics       0.91      0.91      0.91       384\n",
            "         sci.space       0.86      0.87      0.86       378\n",
            "talk.religion.misc       0.69      0.53      0.60       245\n",
            "\n",
            "          accuracy                           0.79      1318\n",
            "         macro avg       0.78      0.77      0.77      1318\n",
            "      weighted avg       0.79      0.79      0.79      1318\n",
            "\n",
            "[[237   7  18  49]\n",
            " [ 14 349  19   2]\n",
            " [ 25  19 327   7]\n",
            " [ 91   8  16 130]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZr0BWzTFm71"
      },
      "source": [
        "Проверим классификатор на полученных ранее tf-idf векторах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYA5YltjLgoB",
        "outputId": "7918471a-e50b-4e24-c60a-77dbcc7899d3"
      },
      "source": [
        "nb = NaiveBayes()\n",
        "\n",
        "nb.fit(xTfidf_train, y_train)\n",
        "pred = nb.predict(xTfidf_test)\n",
        "\n",
        "print(classification_report(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       alt.atheism       0.58      0.78      0.67       311\n",
            "     comp.graphics       0.89      0.91      0.90       384\n",
            "         sci.space       0.78      0.90      0.84       378\n",
            "talk.religion.misc       0.79      0.24      0.37       245\n",
            "\n",
            "          accuracy                           0.75      1318\n",
            "         macro avg       0.76      0.71      0.69      1318\n",
            "      weighted avg       0.77      0.75      0.73      1318\n",
            "\n",
            "[[243  13  40  15]\n",
            " [  7 351  26   0]\n",
            " [ 18  20 339   1]\n",
            " [148  10  28  59]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-8MaAjNEGn"
      },
      "source": [
        "### Сравним с версией из sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcEkWenYLgoC",
        "outputId": "ef6ea490-f406-435b-f127-850bb1d02b02"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB(alpha=4)\n",
        "clf.fit(xcv_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(xcv_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       alt.atheism       0.62      0.75      0.68       311\n",
            "     comp.graphics       0.91      0.91      0.91       384\n",
            "         sci.space       0.83      0.88      0.86       378\n",
            "talk.religion.misc       0.69      0.44      0.54       245\n",
            "\n",
            "          accuracy                           0.78      1318\n",
            "         macro avg       0.76      0.75      0.75      1318\n",
            "      weighted avg       0.78      0.78      0.77      1318\n",
            "\n",
            "[[233   8  28  42]\n",
            " [ 12 350  21   1]\n",
            " [ 20  18 334   6]\n",
            " [109   9  19 108]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCo-Zg6aNBFY",
        "outputId": "a074e57b-f50d-4eda-b2d9-fa47dc8a3d5a"
      },
      "source": [
        "clf = MultinomialNB(alpha=4)\n",
        "clf.fit(xTfidf_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(xTfidf_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "       alt.atheism       0.60      0.65      0.62       311\n",
            "     comp.graphics       0.84      0.93      0.88       384\n",
            "         sci.space       0.64      0.92      0.76       378\n",
            "talk.religion.misc       0.83      0.06      0.11       245\n",
            "\n",
            "          accuracy                           0.70      1318\n",
            "         macro avg       0.73      0.64      0.59      1318\n",
            "      weighted avg       0.73      0.70      0.64      1318\n",
            "\n",
            "[[202  23  83   3]\n",
            " [  1 356  27   0]\n",
            " [  5  25 348   0]\n",
            " [128  19  83  15]]\n"
          ]
        }
      ]
    }
  ]
}